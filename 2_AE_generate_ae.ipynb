{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from utils.df_loader import (\n",
    "    load_adult_df,\n",
    "    load_compas_df,\n",
    "    load_german_df,\n",
    "    load_diabetes_df,\n",
    "    load_breast_cancer_df,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils.preprocessing import preprocess_df\n",
    "from utils.models import load_models\n",
    "\n",
    "import utils.deepfool as util_deepfool\n",
    "import utils.carlini as util_carlini\n",
    "import utils.lowprofool as util_lowprofool\n",
    "import utils.boundary as util_boundary\n",
    "import utils.hopskipjump as util_hopskipjump\n",
    "\n",
    "\n",
    "from utils.save import save_result_as_csv, save_datapoints_as_npy, process_result, process_datapoints\n",
    "\n",
    "seed = 123\n",
    "# tf.random.set_seed(seed)\n",
    "# np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "pd.options.mode.chained_assignment = None # suppress \"SettingWithCopyWarning\" warning\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "print(\"TF version: \", tf.__version__)\n",
    "print(\"Eager execution enabled: \", tf.executing_eagerly())  # False    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_instances = 64 # (1)&(2) 64 - 1 batch\n",
    "\n",
    "RUN_DEEPFOOL = False\n",
    "RUN_CARLINI = False\n",
    "RUN_LOWPROFOOL = False\n",
    "RUN_BOUNDARY = False\n",
    "RUN_HOPSKIPJUMP = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiment(data_type_mixed: bool):\n",
    "    \"\"\"\n",
    "    data_type_mix: True - mixed, False - Numerical only\n",
    "    \"\"\"\n",
    "    if data_type_mixed:\n",
    "        dataset = [\n",
    "        \"adult\",\n",
    "        \"german\",\n",
    "        \"compas\",\n",
    "        ]\n",
    "    else:\n",
    "        dataset = [\n",
    "        \"diabetes\",\n",
    "        # \"breast_cancer\",\n",
    "        ]\n",
    "\n",
    "    #### Select dataset ####\n",
    "    for dataset_name in dataset: \n",
    "        print(f\"Dataset Name: [{dataset_name}]\")\n",
    "        if dataset_name == \"adult\":\n",
    "            dataset_loading_fn = load_adult_df\n",
    "        elif dataset_name == \"german\":\n",
    "            dataset_loading_fn = load_german_df\n",
    "        elif dataset_name == \"compas\":\n",
    "            dataset_loading_fn = load_compas_df\n",
    "        elif dataset_name == \"diabetes\":\n",
    "            dataset_loading_fn = load_diabetes_df\n",
    "        elif dataset_name == \"breast_cancer\":\n",
    "            dataset_loading_fn = load_breast_cancer_df\n",
    "        else:\n",
    "            raise Exception(\"Unsupported dataset\")\n",
    "\n",
    "        df_info = preprocess_df(dataset_loading_fn)\n",
    "\n",
    "        train_df, test_df = train_test_split(\n",
    "            df_info.dummy_df, train_size=0.8, random_state=seed, shuffle=True\n",
    "        )\n",
    "        X_train = np.array(train_df[df_info.ohe_feature_names])\n",
    "        y_train = np.array(train_df[df_info.target_name])\n",
    "        X_test = np.array(test_df[df_info.ohe_feature_names])\n",
    "        y_test = np.array(test_df[df_info.target_name])\n",
    "\n",
    "        ### Load models\n",
    "        models = load_models(X_train.shape[-1], dataset_name)\n",
    "\n",
    "        # DeepFool attack\n",
    "        if RUN_DEEPFOOL:\n",
    "            deepfool_results = util_deepfool.generate_deepfool_result(\n",
    "                    df_info,\n",
    "                    models,\n",
    "                    num_instances,\n",
    "                    X_test,\n",
    "                    y_test,\n",
    "                    models_to_run=[\"lr\",\"svc\",\"nn_2\"],\n",
    "                )\n",
    "            deepfool_datapoints = process_datapoints(deepfool_results)\n",
    "            save_datapoints_as_npy(\"deepfool\", dataset_name, deepfool_datapoints)\n",
    "            deepfool_result_dfs = process_result(deepfool_results, df_info)\n",
    "            save_result_as_csv(\"deepfool\", dataset_name, deepfool_result_dfs)\n",
    "\n",
    "        if RUN_CARLINI:\n",
    "\n",
    "            carlini_l_2_results = util_carlini.generate_carlini_result(\n",
    "                    df_info,\n",
    "                    models,\n",
    "                    num_instances,\n",
    "                    X_test,\n",
    "                    y_test,\n",
    "                    norm=\"l_2\", #[\"l_2\", \"l_inf\"]\n",
    "                    models_to_run=[\"lr\",\"svc\",\"nn_2\"],\n",
    "                )\n",
    "            carlini_l_2_datapoints = process_datapoints(carlini_l_2_results)\n",
    "            save_datapoints_as_npy(\"carlini_l_2\", dataset_name, carlini_l_2_datapoints)\n",
    "            carlini_l_2_result_dfs = process_result(carlini_l_2_results, df_info)\n",
    "            save_result_as_csv(\"carlini_l_2\", dataset_name, carlini_l_2_result_dfs)\n",
    "\n",
    "            carlini_l_inf_results = util_carlini.generate_carlini_result(\n",
    "                    df_info,\n",
    "                    models,\n",
    "                    num_instances,\n",
    "                    X_test,\n",
    "                    y_test,\n",
    "                    norm=\"l_inf\", #[\"l_2\", \"l_inf\"]\n",
    "                    models_to_run=[\"lr\",\"svc\",\"nn_2\"],\n",
    "                )\n",
    "            carlini_l_inf_datapoints = process_datapoints(carlini_l_inf_results)\n",
    "            save_datapoints_as_npy(\"carlini_l_inf\", dataset_name, carlini_l_inf_datapoints)\n",
    "            carlini_l_inf_result_dfs = process_result(carlini_l_inf_results, df_info)\n",
    "            save_result_as_csv(\"carlini_l_inf\", dataset_name, carlini_l_inf_result_dfs)\n",
    "\n",
    "        if not data_type_mixed and RUN_LOWPROFOOL:\n",
    "\n",
    "            lowprofool_l_2_results = util_lowprofool.generate_lowprofool_result(\n",
    "                    df_info,\n",
    "                    models,\n",
    "                    num_instances,\n",
    "                    X_train,\n",
    "                    y_train,\n",
    "                    X_test,\n",
    "                    y_test,\n",
    "                    norm=2, #[int, float, 'inf']\n",
    "                    models_to_run=[\"lr\",\"svc\",\"nn_2\"],\n",
    "                )\n",
    "            lowprofool_l_2_datapoints = process_datapoints(lowprofool_l_2_results)\n",
    "            save_datapoints_as_npy(\"lowprofool_l_2\", dataset_name, lowprofool_l_2_datapoints)\n",
    "            lowprofool_l_2_result_dfs = process_result(lowprofool_l_2_results, df_info)\n",
    "            save_result_as_csv(\"lowprofool_l_2\", dataset_name, lowprofool_l_2_result_dfs)\n",
    "\n",
    "            lowprofool_l_inf_results = util_lowprofool.generate_lowprofool_result(\n",
    "                    df_info,\n",
    "                    models,\n",
    "                    num_instances,\n",
    "                    X_train,\n",
    "                    y_train,\n",
    "                    X_test,\n",
    "                    y_test,\n",
    "                    norm='inf', #[int, float, 'inf']\n",
    "                    models_to_run=[\"lr\",\"svc\",\"nn_2\"],\n",
    "                )\n",
    "            lowprofool_l_inf_datapoints = process_datapoints(lowprofool_l_inf_results)\n",
    "            save_datapoints_as_npy(\"lowprofool_l_inf\", dataset_name, lowprofool_l_inf_datapoints)\n",
    "            lowprofool_l_inf_result_dfs = process_result(lowprofool_l_inf_results, df_info)\n",
    "            save_result_as_csv(\"lowprofool_l_inf\", dataset_name, lowprofool_l_inf_result_dfs)\n",
    "        \n",
    "        if RUN_BOUNDARY:\n",
    "            boundary_results = util_boundary.generate_boundary_result(\n",
    "                    df_info,\n",
    "                    models,\n",
    "                    num_instances,\n",
    "                    X_test,\n",
    "                    y_test,\n",
    "                    models_to_run=[\"dt\",\"rfc\",\"lr\",\"svc\",\"nn\",\"nn_2\"], # \n",
    "                )\n",
    "            boundary_datapoints = process_datapoints(boundary_results)\n",
    "            save_datapoints_as_npy(\"boundary\", dataset_name, boundary_datapoints)\n",
    "            boundary_result_dfs = process_result(boundary_results, df_info)\n",
    "            save_result_as_csv(\"boundary\", dataset_name, boundary_result_dfs)\n",
    "        \n",
    "        if RUN_HOPSKIPJUMP:\n",
    "\n",
    "            hopskipjump_l_2_results = util_hopskipjump.generate_hopskipjump_result(\n",
    "                    df_info,\n",
    "                    models,\n",
    "                    num_instances,\n",
    "                    X_test,\n",
    "                    y_test,\n",
    "                    norm=2,\n",
    "                    models_to_run=[\"dt\",\"rfc\",\"lr\",\"svc\",\"nn\",\"nn_2\"], # \"dt\",\"rfc\",\"lr\",\"svc\",\"nn\",\"nn_2\"\n",
    "            )\n",
    "            hopskipjump_l_2_datapoints = process_datapoints(hopskipjump_l_2_results)\n",
    "            save_datapoints_as_npy(\"hopskipjump_l_2\", dataset_name, hopskipjump_l_2_datapoints)\n",
    "            hopskipjump_l_2_result_dfs = process_result(hopskipjump_l_2_results, df_info)\n",
    "            save_result_as_csv(\"hopskipjump_l_2\", dataset_name, hopskipjump_l_2_result_dfs)\n",
    "\n",
    "\n",
    "            hopskipjump_l_inf_results = util_hopskipjump.generate_hopskipjump_result(\n",
    "                    df_info,\n",
    "                    models,\n",
    "                    num_instances,\n",
    "                    X_test,\n",
    "                    y_test,\n",
    "                    norm=\"inf\",\n",
    "                    models_to_run=[\"dt\",\"rfc\",\"lr\",\"svc\",\"nn\",\"nn_2\"], \n",
    "            )\n",
    "            hopskipjump_l_inf_datapoints = process_datapoints(hopskipjump_l_inf_results)\n",
    "            save_datapoints_as_npy(\"hopskipjump_l_inf\", dataset_name, hopskipjump_l_inf_datapoints)\n",
    "            hopskipjump_l_inf_result_dfs = process_result(hopskipjump_l_inf_results, df_info)\n",
    "            save_result_as_csv(\"hopskipjump_l_inf\", dataset_name, hopskipjump_l_inf_result_dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiment(data_type_mixed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_experiment(data_type_mixed=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "350746cdd709c967d80ca4cb0f1d2cbf04d079be136a05ad7342c703ce6b7c0e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
