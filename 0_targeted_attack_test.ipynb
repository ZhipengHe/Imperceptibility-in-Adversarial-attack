{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mithr\\anaconda3\\envs\\xai\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\mithr\\anaconda3\\envs\\xai\\lib\\site-packages\\art\\estimators\\certification\\__init__.py:13: UserWarning: PyTorch not found. Not importing DeepZ functionality\n",
      "  warnings.warn(\"PyTorch not found. Not importing DeepZ functionality\")\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from utils.df_loader import (\n",
    "    load_adult_df,\n",
    "    load_compas_df,\n",
    "    load_german_df,\n",
    "    load_diabetes_df,\n",
    "    load_breast_cancer_df,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils.preprocessing import preprocess_df\n",
    "from utils.models import (\n",
    "    train_models,\n",
    "    evaluation_test,\n",
    "    save_models,\n",
    "    load_models,\n",
    ")\n",
    "\n",
    "from art.attacks.evasion import DeepFool, CarliniL0Method, CarliniLInfMethod, CarliniL2Method, BoundaryAttack, LowProFool\n",
    "from art.estimators.classification import SklearnClassifier, KerasClassifier\n",
    "\n",
    "from utils.preprocessing import DfInfo\n",
    "from utils.preprocessing import inverse_dummy\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "seed = 42\n",
    "# tf.random.set_seed(seed)\n",
    "# np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "pd.options.mode.chained_assignment = None # suppress \"SettingWithCopyWarning\" warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF version:  2.10.0\n",
      "Eager execution enabled:  False\n"
     ]
    }
   ],
   "source": [
    "TRAIN_MODEL = False # (1)True(2)False\n",
    "RUN_ART = True\n",
    "num_instances = 64 # (1)&(2) 20\n",
    "\n",
    "if RUN_ART:\n",
    "    tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "print(\"TF version: \", tf.__version__)\n",
    "print(\"Eager execution enabled: \", tf.executing_eagerly())  # False    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Name: [breast_cancer]\n"
     ]
    }
   ],
   "source": [
    "#### Select dataset ####\n",
    "for dataset_name in [\n",
    "    # \"adult\",\n",
    "    # \"german\",\n",
    "    #  \"compas\",\n",
    "    # \"diabetes\",\n",
    "    \"breast_cancer\",\n",
    "]:  # [adult, german, compas]\n",
    "    print(f\"Dataset Name: [{dataset_name}]\")\n",
    "    if dataset_name == \"adult\":\n",
    "        dataset_loading_fn = load_adult_df\n",
    "    elif dataset_name == \"german\":\n",
    "        dataset_loading_fn = load_german_df\n",
    "    elif dataset_name == \"compas\":\n",
    "        dataset_loading_fn = load_compas_df\n",
    "    elif dataset_name == \"diabetes\":\n",
    "        dataset_loading_fn = load_diabetes_df\n",
    "    elif dataset_name == \"breast_cancer\":\n",
    "        dataset_loading_fn = load_breast_cancer_df\n",
    "    else:\n",
    "        raise Exception(\"Unsupported dataset\")\n",
    "\n",
    "    df_info = preprocess_df(dataset_loading_fn)\n",
    "\n",
    "    train_df, test_df = train_test_split(\n",
    "        df_info.dummy_df, train_size=0.8, random_state=seed, shuffle=True\n",
    "    )\n",
    "    X_train = np.array(train_df[df_info.ohe_feature_names])\n",
    "    y_train = np.array(train_df[df_info.target_name])\n",
    "    X_test = np.array(test_df[df_info.ohe_feature_names])\n",
    "    y_test = np.array(test_df[df_info.target_name])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mithr\\anaconda3\\envs\\xai\\lib\\site-packages\\keras\\engine\\training_v1.py:2356: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  updates=self.state_updates,\n"
     ]
    }
   ],
   "source": [
    "### Load models\n",
    "models = load_models(X_train.shape[-1], dataset_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_instances = 64 # (1)&(2) 20\n",
    "\n",
    "X_test_re=X_test[0:num_instances]\n",
    "y_test_re=y_test[0:num_instances]\n",
    "y_test_in=1-y_test_re\n",
    "\n",
    "# y_test_in_ohe = np.zeros((y_test_in.size, 2))\n",
    "# y_test_in_ohe[np.arange(y_test_in.size), y_test_in] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C&W L_2: 100%|██████████| 1/1 [00:02<00:00,  2.04s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tar_attack = CarliniL2Method(classifier=KerasClassifier(models['nn_2'], clip_values=(0,1)), verbose= True,  targeted=True, batch_size=64)\n",
    "x_adv_tar = tar_attack.generate(X_test_re,y_test_in)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C&W L_2: 100%|██████████| 1/1 [00:02<00:00,  2.30s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "un_attack = CarliniL2Method(classifier=KerasClassifier(models['nn_2'], clip_values=(0,1)), verbose= True,  targeted=False, batch_size=64)\n",
    "x_adv_un = un_attack.generate(X_test_re, y_test_re)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tar_predictions = models['nn_2'].predict(x_adv_tar).argmax(axis=1).flatten().astype(int)\n",
    "\n",
    "un_predictions = models['nn_2'].predict(x_adv_un).argmax(axis=1).flatten().astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tar_predictions == un_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "un_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 | packaged by conda-forge | (main, Nov 24 2022, 14:07:00) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5372a90187f05abdb7392726881158217660b0fad03ab7bdeca2ae0a854d393b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
