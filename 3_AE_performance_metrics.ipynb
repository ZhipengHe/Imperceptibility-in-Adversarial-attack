{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"-1\" \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from utils.preprocessing import preprocess_df\n",
    "from utils.df_loader import load_adult_df, load_compas_df, load_german_df, load_diabetes_df, load_breast_cancer_df\n",
    "from utils.evaluation import get_evaluations, EvaluationMatrix\n",
    "\n",
    "from utils.load import load_result_from_csv, load_datapoints_from_npy\n",
    "from utils.models import load_models\n",
    "from utils.models import save_model_performance\n",
    "\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "pd.options.mode.chained_assignment = None # suppress \"SettingWithCopyWarning\" warning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "        # \"adult\",\n",
    "        # \"german\",\n",
    "        # \"compas\",\n",
    "        # \"diabetes\",\n",
    "        \"breast_cancer\",\n",
    "        ]\n",
    "\n",
    "models = [\"dt\",\"gbc\",\"lr\",\"svc\",\"nn_2\"] # \"dt\",\"gbc\",\"lr\",\"svc\",\n",
    "\n",
    "\n",
    "attack_list = [\n",
    "        'deepfool', \n",
    "        'carlini_l_2', \n",
    "        'carlini_l_inf', \n",
    "        'lowprofool_l_2', \n",
    "        'lowprofool_l_inf', \n",
    "        'fgsm_l_1',\n",
    "        'fgsm_l_2',\n",
    "        'fgsm_l_inf',\n",
    "        'bim',\n",
    "        # 'boundary', \n",
    "        # 'hopskipjump_l_2', 'hopskipjump_l_inf'\n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loading_fn(dataset_name):\n",
    "    if dataset_name == 'adult':\n",
    "        dataset_loading_fn = load_adult_df\n",
    "    elif dataset_name == 'german':\n",
    "        dataset_loading_fn = load_german_df\n",
    "    elif dataset_name == 'compas':\n",
    "        dataset_loading_fn = load_compas_df\n",
    "    elif dataset_name == 'diabetes':\n",
    "        dataset_loading_fn = load_diabetes_df\n",
    "    elif dataset_name == 'breast_cancer':\n",
    "        dataset_loading_fn = load_breast_cancer_df\n",
    "    else:\n",
    "        raise Exception(\"Unsupported dataset\")\n",
    "    return dataset_loading_fn\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dataset_name in datasets:\n",
    "#     for attack in attack_list:\n",
    "#         folder_name = f\"{attack}_{dataset_name}\"\n",
    "\n",
    "#         ## check if the folder exist\n",
    "\n",
    "#         if os.path.isdir(f'./results/{folder_name}'):\n",
    "#             for model_name in models:\n",
    "\n",
    "#                 dfs = []\n",
    "#                 file_name = f'{folder_name}_{model_name}_result.csv'\n",
    "#                 destination_path = f'./results/{folder_name}/{file_name}'\n",
    "\n",
    "#                 if os.path.isfile(f'./results/{folder_name}/{folder_name}_{model_name}_result_1.csv'):\n",
    "#                     for i in range(0,10):\n",
    "#                         dataset_path = (\n",
    "#                             f\"{attack}_{dataset_name}_{model_name}_result_{i}.csv\"\n",
    "#                         )\n",
    "#                         dfs.append(pd.read_csv(f\"./results/{folder_name}/{dataset_path}\"))\n",
    "\n",
    "#                     ### Combine dfs\n",
    "#                     complete_df = pd.DataFrame([], columns=dfs[0].columns)\n",
    "#                     for l in range(len(dfs[0])):\n",
    "#                         for df in dfs:\n",
    "#                             complete_df = complete_df.append(df.iloc[l : l + 1])\n",
    "\n",
    "#                     ### Save dfs\n",
    "#                     complete_df.to_csv(destination_path)\n",
    "#                     print(f\"Have saved combined sheet to {destination_path}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check wheather white-box attack output same results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def are_ndarrays_same(ndarrays):\n",
    "#   # Create an empty matrix of size len(ndarrays) x len(ndarrays)\n",
    "#   results_matrix = np.empty((len(ndarrays), len(ndarrays)))\n",
    "\n",
    "#   # Iterate through each pair of ndarrays and check if they are the same\n",
    "#   for i in range(len(ndarrays)):\n",
    "#     for j in range(len(ndarrays)):\n",
    "#       if i == j:\n",
    "#         # If the indices are the same, mark it as True in the results matrix\n",
    "#         results_matrix[i][j] = True\n",
    "#       else:\n",
    "#         # Compare the ndarrays using the numpy.array_equal function\n",
    "#         results_matrix[i][j] = np.array_equal(ndarrays[i], ndarrays[j])\n",
    "#   return results_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for dataset_name in datasets:\n",
    "#     for attack in attack_list:\n",
    "#         for model_name in models:\n",
    "#             ndarrays = []\n",
    "#             for running_times in range(0,10):\n",
    "#                 ndarrays.append(load_datapoints_from_npy(attack, dataset_name, model_name, running_times, adv=True))\n",
    "#             print(f'{dataset_name} - {attack} - {model_name}')\n",
    "#             print(are_ndarrays_same(ndarrays).min())\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dic_from_metric(all_metric):\n",
    "\n",
    "    dataset_arr = []\n",
    "    attack_arr = []\n",
    "    model_arr = []\n",
    "    metric_arr = []\n",
    "    value_arr = []\n",
    "\n",
    "    for dataset, dic1 in all_metric.items():\n",
    "        for attack, dic2 in dic1.items():\n",
    "            for model, dic3 in dic2.items():\n",
    "                for metric, value in dic3.items():\n",
    "                    dataset_arr.append(dataset)\n",
    "                    attack_arr.append(attack)\n",
    "                    model_arr.append(model)\n",
    "                    metric_arr.append(metric)\n",
    "                    value_arr.append(value)\n",
    "\n",
    "    table = {\n",
    "            'Dataset': dataset_arr,\n",
    "            'Attack': attack_arr,\n",
    "            'Model': model_arr,\n",
    "            'Metric': metric_arr,\n",
    "            'Value': value_arr,\n",
    "        }\n",
    "\n",
    "    return table\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Have saved file to results/deepfool_breast_cancer/eval_deepfool_breast_cancer_lr_result_0.csv\n",
      "Have saved file to results/deepfool_breast_cancer/eval_deepfool_breast_cancer_svc_result_0.csv\n",
      "Have saved file to results/deepfool_breast_cancer/eval_deepfool_breast_cancer_nn_2_result_0.csv\n",
      "Have saved file to results/carlini_l_2_breast_cancer/eval_carlini_l_2_breast_cancer_lr_result_0.csv\n",
      "Have saved file to results/carlini_l_2_breast_cancer/eval_carlini_l_2_breast_cancer_svc_result_0.csv\n",
      "Have saved file to results/carlini_l_2_breast_cancer/eval_carlini_l_2_breast_cancer_nn_2_result_0.csv\n",
      "Have saved file to results/carlini_l_inf_breast_cancer/eval_carlini_l_inf_breast_cancer_lr_result_0.csv\n",
      "Have saved file to results/carlini_l_inf_breast_cancer/eval_carlini_l_inf_breast_cancer_svc_result_0.csv\n",
      "Have saved file to results/carlini_l_inf_breast_cancer/eval_carlini_l_inf_breast_cancer_nn_2_result_0.csv\n",
      "Have saved file to results/lowprofool_l_2_breast_cancer/eval_lowprofool_l_2_breast_cancer_lr_result_0.csv\n",
      "Have saved file to results/lowprofool_l_2_breast_cancer/eval_lowprofool_l_2_breast_cancer_svc_result_0.csv\n",
      "Have saved file to results/lowprofool_l_2_breast_cancer/eval_lowprofool_l_2_breast_cancer_nn_2_result_0.csv\n",
      "Have saved file to results/lowprofool_l_inf_breast_cancer/eval_lowprofool_l_inf_breast_cancer_lr_result_0.csv\n",
      "Have saved file to results/lowprofool_l_inf_breast_cancer/eval_lowprofool_l_inf_breast_cancer_svc_result_0.csv\n",
      "Have saved file to results/lowprofool_l_inf_breast_cancer/eval_lowprofool_l_inf_breast_cancer_nn_2_result_0.csv\n"
     ]
    }
   ],
   "source": [
    "#### Select dataset ####\n",
    "\n",
    "all_metric = {}\n",
    "\n",
    "for dataset_name in datasets:\n",
    "    all_metric[dataset_name]={}\n",
    "\n",
    "    df_info = preprocess_df(get_loading_fn(dataset_name))\n",
    "    for attack in attack_list:\n",
    "        all_metric[dataset_name][attack]={}\n",
    "\n",
    "        folder_name = f'{attack}_{dataset_name}'\n",
    "        for model_name in models:\n",
    "\n",
    "            file_name = f'{folder_name}_{model_name}_result_0.csv'\n",
    "            result_path = f'./results/{folder_name}/{file_name}'\n",
    "            if os.path.isfile(result_path):\n",
    "                result_df = pd.read_csv(result_path)\n",
    "                evaluation_df, metric = get_evaluations(result_df=result_df, \n",
    "                    df_info=df_info, \n",
    "                    matrix = [\n",
    "                        EvaluationMatrix.L1, \n",
    "                        EvaluationMatrix.L2, \n",
    "                        EvaluationMatrix.Linf,\n",
    "                        EvaluationMatrix.MAD, \n",
    "                        EvaluationMatrix.Mahalanobis,\n",
    "                        EvaluationMatrix.Sparsity, \n",
    "                        EvaluationMatrix.Perturbation_Sensitivity,\n",
    "                        EvaluationMatrix.Neighbour_Distance,\n",
    "                        ])\n",
    "                \n",
    "                all_metric[dataset_name][attack][model_name] = metric\n",
    "\n",
    "                csv_save_result_path = f'results/{folder_name}/eval_{file_name}'\n",
    "                evaluation_df.to_csv(csv_save_result_path)\n",
    "                print(f\"Have saved file to {csv_save_result_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_results = pd.DataFrame.from_dict(get_dic_from_metric(all_metric))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_results.to_csv(f\"./results/{datasets[0]}_evaluation_results.csv\",index=False)\n",
    "# im_results.to_csv(f\"./results/diabetes_evaluation_results.csv\",index=False)\n",
    "# im_results.to_csv(f\"./results/carlini_l2_adult_table.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Model</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>deepfool</td>\n",
       "      <td>lr</td>\n",
       "      <td>eval_L1</td>\n",
       "      <td>8.025208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>deepfool</td>\n",
       "      <td>lr</td>\n",
       "      <td>eval_L2</td>\n",
       "      <td>1.700544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>deepfool</td>\n",
       "      <td>lr</td>\n",
       "      <td>eval_Linf</td>\n",
       "      <td>0.523994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>deepfool</td>\n",
       "      <td>lr</td>\n",
       "      <td>eval_MAD</td>\n",
       "      <td>2.507095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>deepfool</td>\n",
       "      <td>lr</td>\n",
       "      <td>eval_Mahalanobis</td>\n",
       "      <td>0.842675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>lowprofool_l_inf</td>\n",
       "      <td>nn_2</td>\n",
       "      <td>eval_MAD</td>\n",
       "      <td>2.547293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>lowprofool_l_inf</td>\n",
       "      <td>nn_2</td>\n",
       "      <td>eval_Mahalanobis</td>\n",
       "      <td>0.454430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>lowprofool_l_inf</td>\n",
       "      <td>nn_2</td>\n",
       "      <td>eval_Sparsity</td>\n",
       "      <td>29.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>lowprofool_l_inf</td>\n",
       "      <td>nn_2</td>\n",
       "      <td>eval_Perturbation_Sensitivity</td>\n",
       "      <td>3.270870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>lowprofool_l_inf</td>\n",
       "      <td>nn_2</td>\n",
       "      <td>eval_Neighbour_Distance</td>\n",
       "      <td>1.408317</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>120 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Dataset            Attack Model                         Metric  \\\n",
       "0    breast_cancer          deepfool    lr                        eval_L1   \n",
       "1    breast_cancer          deepfool    lr                        eval_L2   \n",
       "2    breast_cancer          deepfool    lr                      eval_Linf   \n",
       "3    breast_cancer          deepfool    lr                       eval_MAD   \n",
       "4    breast_cancer          deepfool    lr               eval_Mahalanobis   \n",
       "..             ...               ...   ...                            ...   \n",
       "115  breast_cancer  lowprofool_l_inf  nn_2                       eval_MAD   \n",
       "116  breast_cancer  lowprofool_l_inf  nn_2               eval_Mahalanobis   \n",
       "117  breast_cancer  lowprofool_l_inf  nn_2                  eval_Sparsity   \n",
       "118  breast_cancer  lowprofool_l_inf  nn_2  eval_Perturbation_Sensitivity   \n",
       "119  breast_cancer  lowprofool_l_inf  nn_2        eval_Neighbour_Distance   \n",
       "\n",
       "         Value  \n",
       "0     8.025208  \n",
       "1     1.700544  \n",
       "2     0.523994  \n",
       "3     2.507095  \n",
       "4     0.842675  \n",
       "..         ...  \n",
       "115   2.547293  \n",
       "116   0.454430  \n",
       "117  29.937500  \n",
       "118   3.270870  \n",
       "119   1.408317  \n",
       "\n",
       "[120 rows x 5 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "im_results"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def compare_ndarrays(arr1, arr2):\n",
    "    if arr1.shape != arr2.shape:\n",
    "        raise ValueError(\"Input arrays have different shapes\")\n",
    "    return np.where(arr1 == arr2, 0, 1)\n",
    "\n",
    "def get_attack_success_accuracy(models, model, input_array, adv_array, groundtruth):\n",
    "\n",
    "    if model == 'dt':\n",
    "        predictions = models['dt'].predict(input_array)\n",
    "        adv_predictions = models['dt'].predict(adv_array)\n",
    "    if model == 'rfc':\n",
    "        predictions = models['rfc'].predict(input_array)\n",
    "        adv_predictions = models['rfc'].predict(adv_array)\n",
    "    if model == 'svc':\n",
    "        predictions = models['svc'].predict(input_array)\n",
    "        adv_predictions = models['svc'].predict(adv_array)\n",
    "    if model == 'lr':\n",
    "        predictions = models['lr'].predict(input_array)\n",
    "        adv_predictions = models['lr'].predict(adv_array)\n",
    "    if model == 'gbc':\n",
    "        predictions = models['gbc'].predict(input_array)\n",
    "        adv_predictions = models['gbc'].predict(adv_array)\n",
    "    if model == 'nn':\n",
    "        predictions = (models['nn'].predict(input_array) > 0.5).flatten().astype(int)\n",
    "        adv_predictions = (models['nn'].predict(adv_array) > 0.5).flatten().astype(int)\n",
    "    if model == 'nn_2':\n",
    "        predictions = models['nn_2'].predict(input_array).argmax(axis=1).flatten().astype(int)\n",
    "        adv_predictions = models['nn_2'].predict(adv_array).argmax(axis=1).flatten().astype(int)\n",
    "\n",
    "\n",
    "    pred_attack_success = compare_ndarrays(predictions, adv_predictions).mean()\n",
    "    groundtruth_attack_success = compare_ndarrays(groundtruth, adv_predictions).mean()\n",
    "    original_accuracy = accuracy_score(groundtruth, predictions)\n",
    "    robust_accuracy = accuracy_score(groundtruth, adv_predictions)\n",
    "\n",
    "\n",
    "\n",
    "    dict = {\n",
    "        'pred_attack_success':pred_attack_success, \n",
    "            'original_accuracy': original_accuracy, \n",
    "            'robust_accuracy': robust_accuracy}\n",
    "\n",
    "    print(dict)\n",
    "    return dict\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.models import save_model_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 48ms/step\n",
      "{'pred_attack_success': 1.0, 'original_accuracy': 0.984375, 'robust_accuracy': 0.015625}\n",
      "{'pred_attack_success': 1.0, 'original_accuracy': 0.984375, 'robust_accuracy': 0.015625}\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "{'pred_attack_success': 1.0, 'original_accuracy': 0.96875, 'robust_accuracy': 0.03125}\n",
      "{'pred_attack_success': 0.921875, 'original_accuracy': 0.984375, 'robust_accuracy': 0.09375}\n",
      "{'pred_attack_success': 0.03125, 'original_accuracy': 0.984375, 'robust_accuracy': 0.953125}\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "{'pred_attack_success': 0.859375, 'original_accuracy': 0.96875, 'robust_accuracy': 0.171875}\n",
      "{'pred_attack_success': 0.125, 'original_accuracy': 0.984375, 'robust_accuracy': 0.890625}\n",
      "{'pred_attack_success': 0.140625, 'original_accuracy': 0.984375, 'robust_accuracy': 0.875}\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "{'pred_attack_success': 0.234375, 'original_accuracy': 0.96875, 'robust_accuracy': 0.796875}\n",
      "{'pred_attack_success': 1.0, 'original_accuracy': 0.984375, 'robust_accuracy': 0.015625}\n",
      "{'pred_attack_success': 1.0, 'original_accuracy': 0.984375, 'robust_accuracy': 0.015625}\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "{'pred_attack_success': 1.0, 'original_accuracy': 0.96875, 'robust_accuracy': 0.03125}\n",
      "{'pred_attack_success': 1.0, 'original_accuracy': 0.984375, 'robust_accuracy': 0.015625}\n",
      "{'pred_attack_success': 1.0, 'original_accuracy': 0.984375, 'robust_accuracy': 0.015625}\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "{'pred_attack_success': 1.0, 'original_accuracy': 0.96875, 'robust_accuracy': 0.03125}\n",
      "{'pred_attack_success': 0.03125, 'original_accuracy': 0.984375, 'robust_accuracy': 0.953125}\n",
      "{'pred_attack_success': 0.03125, 'original_accuracy': 0.984375, 'robust_accuracy': 0.953125}\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "{'pred_attack_success': 0.125, 'original_accuracy': 0.96875, 'robust_accuracy': 0.90625}\n",
      "{'pred_attack_success': 0.25, 'original_accuracy': 0.984375, 'robust_accuracy': 0.765625}\n",
      "{'pred_attack_success': 0.5, 'original_accuracy': 0.984375, 'robust_accuracy': 0.515625}\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "{'pred_attack_success': 0.6875, 'original_accuracy': 0.96875, 'robust_accuracy': 0.34375}\n",
      "{'pred_attack_success': 0.984375, 'original_accuracy': 0.984375, 'robust_accuracy': 0.03125}\n",
      "{'pred_attack_success': 1.0, 'original_accuracy': 0.984375, 'robust_accuracy': 0.015625}\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "{'pred_attack_success': 1.0, 'original_accuracy': 0.96875, 'robust_accuracy': 0.03125}\n",
      "{'pred_attack_success': 0.984375, 'original_accuracy': 0.984375, 'robust_accuracy': 0.03125}\n",
      "{'pred_attack_success': 1.0, 'original_accuracy': 0.984375, 'robust_accuracy': 0.015625}\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "{'pred_attack_success': 1.0, 'original_accuracy': 0.96875, 'robust_accuracy': 0.03125}\n"
     ]
    }
   ],
   "source": [
    "#### Select dataset ####\n",
    "\n",
    "all_performance = {}\n",
    "\n",
    "for dataset_name in datasets:\n",
    "    all_performance[dataset_name]={}\n",
    "\n",
    "    df_info = preprocess_df(get_loading_fn(dataset_name))\n",
    "    train_df, test_df = train_test_split(\n",
    "        df_info.dummy_df, train_size=0.8, random_state=seed, shuffle=True\n",
    "    )\n",
    "    X_train = np.array(train_df[df_info.ohe_feature_names])\n",
    "    y_train = np.array(train_df[df_info.target_name])\n",
    "    X_test = np.array(test_df[df_info.ohe_feature_names])\n",
    "    y_test = np.array(test_df[df_info.target_name])\n",
    "\n",
    "    X_test_num = len(X_test) - (len(X_test)%64)\n",
    "    X_test_re=X_test[0:X_test_num]\n",
    "    y_test_num = len(y_test) - (len(y_test)%64)\n",
    "    y_test_re=y_test[0:y_test_num]\n",
    "\n",
    "    predict_model = load_models(X_train.shape[-1], dataset_name)\n",
    "\n",
    "    for attack in attack_list:\n",
    "        all_performance[dataset_name][attack]={}\n",
    "\n",
    "        folder_name = f'{attack}_{dataset_name}'\n",
    "        for model_name in models:\n",
    "\n",
    "            adv_arr_name = f'{folder_name}_{model_name}_arr_adv_0.npy'\n",
    "            adv_arr_path = f'./datapoints/{folder_name}/{adv_arr_name}'\n",
    "            \n",
    "            if os.path.isfile(adv_arr_path):\n",
    "                adv_arr = load_datapoints_from_npy(attack, dataset_name, model_name, 0, adv=True)\n",
    "\n",
    "                all_performance[dataset_name][attack][model_name] = get_attack_success_accuracy(predict_model, model_name, X_test_re, adv_arr, y_test_re)\n",
    "\n",
    "                # m = save_model_performance(predict_model,dataset_name, adv_arr, y_test_re)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "performance_df = pd.DataFrame.from_dict(get_dic_from_metric(all_performance))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance_df.to_csv(f\"./results/{datasets[0]}_performance_results.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Model</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>deepfool</td>\n",
       "      <td>lr</td>\n",
       "      <td>pred_attack_success</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>deepfool</td>\n",
       "      <td>lr</td>\n",
       "      <td>original_accuracy</td>\n",
       "      <td>0.984375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>deepfool</td>\n",
       "      <td>lr</td>\n",
       "      <td>robust_accuracy</td>\n",
       "      <td>0.015625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>deepfool</td>\n",
       "      <td>svc</td>\n",
       "      <td>pred_attack_success</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>deepfool</td>\n",
       "      <td>svc</td>\n",
       "      <td>original_accuracy</td>\n",
       "      <td>0.984375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>bim</td>\n",
       "      <td>svc</td>\n",
       "      <td>original_accuracy</td>\n",
       "      <td>0.984375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>bim</td>\n",
       "      <td>svc</td>\n",
       "      <td>robust_accuracy</td>\n",
       "      <td>0.015625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>bim</td>\n",
       "      <td>nn_2</td>\n",
       "      <td>pred_attack_success</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>bim</td>\n",
       "      <td>nn_2</td>\n",
       "      <td>original_accuracy</td>\n",
       "      <td>0.968750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>breast_cancer</td>\n",
       "      <td>bim</td>\n",
       "      <td>nn_2</td>\n",
       "      <td>robust_accuracy</td>\n",
       "      <td>0.031250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>81 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Dataset    Attack Model               Metric     Value\n",
       "0   breast_cancer  deepfool    lr  pred_attack_success  1.000000\n",
       "1   breast_cancer  deepfool    lr    original_accuracy  0.984375\n",
       "2   breast_cancer  deepfool    lr      robust_accuracy  0.015625\n",
       "3   breast_cancer  deepfool   svc  pred_attack_success  1.000000\n",
       "4   breast_cancer  deepfool   svc    original_accuracy  0.984375\n",
       "..            ...       ...   ...                  ...       ...\n",
       "76  breast_cancer       bim   svc    original_accuracy  0.984375\n",
       "77  breast_cancer       bim   svc      robust_accuracy  0.015625\n",
       "78  breast_cancer       bim  nn_2  pred_attack_success  1.000000\n",
       "79  breast_cancer       bim  nn_2    original_accuracy  0.968750\n",
       "80  breast_cancer       bim  nn_2      robust_accuracy  0.031250\n",
       "\n",
       "[81 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "performance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "350746cdd709c967d80ca4cb0f1d2cbf04d079be136a05ad7342c703ce6b7c0e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
